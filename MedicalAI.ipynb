{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_token = {\"username\":\"\", \"key\":\"\"} #get these from your kaggle account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./chest-xray-pneumonia.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_random_image (dir, condition):\n",
    "    placeholder=''\n",
    "    if condition=='n':\n",
    "        placeholder='NORMAL'\n",
    "    elif condition=='p':\n",
    "        placeholder='PNEUMONIA'\n",
    "\n",
    "    else:\n",
    "        raise Exception (\"Sorry Invalid Condition\")\n",
    "    folder = f\"./data/chest_xray/{dir}/{placeholder}/*.jpeg\"\n",
    "    img_paths = glob.glob(folder)\n",
    "    max_length = len(img_paths)\n",
    "    randomNumber = random.randint(0, max_length)\n",
    "    \n",
    "    for index,item in enumerate(img_paths, start=1):\n",
    "        if index==randomNumber:\n",
    "            print(index,item)\n",
    "            image=plt.imread(item)\n",
    "            readyImage=plt.imshow(image)\n",
    "            return readyImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_image(\"train\", \"p\")\n",
    "# get_random_image(\"val\", \"p\")\n",
    "# get_random_image(\"val\", \"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be extracting images to their correct folder structure AND resizing the images.\n",
    "train_pneumonia0.jpeg, train_normal0.jpeg\n",
    "In Sagemaker we will be doing transfer learning using the Image classifier which relies on the RESNET framework\n",
    "The images have to be 224 by 224 and 3 colour channels - RGB\n",
    "When using matplotlib, greyscale and B&W images are savaed and opened withe the default colour map - vidris\n",
    "We need to save images in grayscale the actual colour code of x-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the mode L currently - 2 colour channels\n",
    "# When we specify the configurations for our training job in Sagemaker, we will specify that inputs should be 224 by 224 by 3\n",
    "\n",
    "from PIL import Image\n",
    "image=Image.open('path to chest x-ray image')\n",
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNGs have RGBA - 4 colour channels, when this happens change it before starting the training job\n",
    "import PIL.Image\n",
    "rgba_image = PIL.Image.open('path to rgba image')\n",
    "rgb_image = rgba_image.convert('RGB')\n",
    "print(rgb_image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you open the pneumonia folder you will see every image label starts with \"person\"\n",
    "# When you open the normal folder you will see every image label starts with \"IM\"\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "folder = '.data/chest_xray/train/*/*.jpeg'\n",
    "\n",
    "counterPneu=0\n",
    "counterNormal=0\n",
    "\n",
    "img_paths = glob.glob(folder)\n",
    "\n",
    "for i in img_paths:\n",
    "    if \"person\" in i:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/train' + '/train_pneumonia' + str(counterPneu) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterPneu+=1\n",
    "    else:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/train' + '/train_normal' + str(counterNormal) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterNormal+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "folder = '.data/chest_xray/test/*/*.jpeg'\n",
    "\n",
    "counterPneu=0\n",
    "counterNormal=0\n",
    "\n",
    "img_paths = glob.glob(folder)\n",
    "\n",
    "for i in img_paths:\n",
    "    if \"person\" in i:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/test' + '/test_pneumonia' + str(counterPneu) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterPneu+=1\n",
    "    else:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/test' + '/test_normal' + str(counterNormal) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterNormal+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "\n",
    "folder = '.data/chest_xray/val/*/*.jpeg'\n",
    "\n",
    "counterPneu=0\n",
    "counterNormal=0\n",
    "\n",
    "img_paths = glob.glob(folder)\n",
    "\n",
    "for i in img_paths:\n",
    "    if \"person\" in i:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/val' + '/val_pneumonia' + str(counterPneu) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterPneu+=1\n",
    "    else:\n",
    "        full_size_image = Image.open(i)\n",
    "        im = full_size_image.resize((224, 224))\n",
    "        plt.imsave(fname='./data/chest_xray/val' + '/val_normal' + str(counterNormal) + '.jpeg', arr=im, format='jpeg', cmap='gray')\n",
    "        counterNormal+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFTER RESIZING AND MAKING GRAY, WE CAN NOW DELETE THE NORMAL AND PNEUMONIA FOLDERS FROM THE TEST,TRAIN AND VAL FOLDERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are creating a dataframe so that we can visualize on seaborn:\n",
    "# 3 columns - folder, lung condition, file path\n",
    "# row example: val, normal, filepath.jpeg\n",
    "# row example: test, pneumonia, filepath.jpeg\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "folder = './data/chest_xray/*/*.jpeg'\n",
    "\n",
    "category = []\n",
    "condition_of_lung = []\n",
    "filenames = []\n",
    "\n",
    "all_files = glob.glob(folder)\n",
    "\n",
    "for filename in all_files: \n",
    "    if \"train\" in filename:\n",
    "        if \"pneumonia\" in filename:\n",
    "            category.append(\"train\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"pneumonia\")\n",
    "        elif \"normal\" in filename:\n",
    "            category.append(\"train\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"normal\")\n",
    "    elif \"test\" in filename:\n",
    "        if \"pneumonia\" in filename:\n",
    "            category.append(\"test\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"pneumonia\")\n",
    "        elif \"normal\" in filename:\n",
    "            category.append(\"test\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"normal\")\n",
    "    elif \"val\" in filename:\n",
    "        if \"pneumonia\" in filename:\n",
    "            category.append(\"val\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"pneumonia\")\n",
    "        elif \"normal\" in filename:\n",
    "            category.append(\"val\")\n",
    "            filenames.append(filename)\n",
    "            condition_of_lung.append(\"normal\")\n",
    "\n",
    "all_data_df = pd.DataFrame ({\"dataset type\":category, \"x-ray reult\":condition_of_lung, \"filename\":filenames})\n",
    "print(all_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.catplot(x=\"x-ray result\", col=\"dataset type\", kind=\"count\", palette=\"ch:.55\", data= all_data_df, legend=True)\n",
    "\n",
    "for i in range (0.3):\n",
    "    ax = g.facet_axis(0,i)\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x()+0.3,\n",
    "                p.get_height()*1.05,\n",
    "                '{0:0f}'.format(p.get_height()),\n",
    "                color = 'black',\n",
    "                rotation='horizontal',\n",
    "                size='large')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lst filess\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "train_folder = './data/chest_xray/train/*.jpeg'\n",
    "train_df_lst = pd.DataFrame(columns=['labels', 's3_path'], dtype=object)\n",
    "train_imgs_path = glob.glob(train_folder)\n",
    "counter = 0\n",
    "class_arg = ''\n",
    "\n",
    "for i in train_imgs_path:\n",
    "    if \"pneumonia\" in i:    \n",
    "        class_arg = 1\n",
    "    else:\n",
    "        class_arg = 0\n",
    "    train_df_lst.loc[counter] = [class_arg, os.path.basename(i)]\n",
    "    counter+=1\n",
    "print(train_df_lst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lst filess\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "test_folder = './data/chest_xray/test/*.jpeg'\n",
    "test_df_lst = pd.DataFrame(columns=['labels', 's3_path'],dtype=object)\n",
    "test_imgs_path = glob.glob(test_folder)\n",
    "counter = 0\n",
    "class_arg = ''\n",
    "\n",
    "for i in test_imgs_path:\n",
    "    if \"pneumonia\" in i:\n",
    "        class_arg = 1\n",
    "    else:\n",
    "        class_arg = 0\n",
    "    test_df_lst.loc[counter] = [class_arg, os.path.basename(i)]\n",
    "    counter+=1\n",
    "print(test_df_lst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_lst(df,prefix):\n",
    "    return df [[\"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep='\\t', index=True, header=False\n",
    "    )\n",
    "\n",
    "save_to_lst(train_df_lst.copy(),\"train\")\n",
    "save_to_lst(test_df_lst.copy, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "bucket = 's3_bucket_name' # your bucket name\n",
    "print(\"bucket:{}\".format(bucket))\n",
    "region = 'eu-central-1' # or the region you are working on\n",
    "print(\"region:{}\".format(region))\n",
    "roleArn = 'arn:aws:s3:::s3_bucket_name' #your bucket arn\n",
    "print(\"roleArn:{}\".format(roleArn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync .data/chest_xray/train s3://${DEFAULT_S3_BUCKET}/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync .data/chest_xray/test s3://${DEFAULT_S3_BUCKET}/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\"train.lst\").upload_file('./train.lst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(\"test.lst\").upload_file('./test.lst')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "sess=sagemaker.Session()\n",
    "\n",
    "algorithm_image=image_uris.retrieve(\n",
    "    region = boto3.Session().region_name,\n",
    "    framework=\"image-classification\"\n",
    ")\n",
    "\n",
    "s3_output_location = f\"s3://{bucket}/models/image_model\"\n",
    "print(algorithm_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model = sagemaker.estimator.Estimator(\n",
    "    algorithm_image, \n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    volume_size=50,\n",
    "    max_run=432000\n",
    "    input_mode=\"File\", # for pipe mode you need protobuf format, best with millions of data records\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session = sess\n",
    ")\n",
    "\n",
    "print (img_classifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "count = 0\n",
    "\n",
    "for filepath in glob.glob('./data/chest_xray/train/*.jpeg'):\n",
    "    count+=1\n",
    "print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model.set_hyperparameters(\n",
    "    image_shape=\"3,224,224\", # sagemaker will transform the gray scale to RGB due to the specification made\n",
    "    num_classes=2,\n",
    "    use_pretrained_model=1,\n",
    "    num_training_samples=count,\n",
    "    augmentation_type='crop_color_transformation',\n",
    "    epochs=15, # for enterprise bare minimum is 50 epochs to ensure high accuracy\n",
    "    early_stopping=True,\n",
    "    early_stopping_min_epochs=8, # if epochs were 50, this would be 30\n",
    "    early_stopping_patience=5,\n",
    "    early_stopping_tolerance=0.0, # if (improvement in accuracy / previous best accuracy) is less than early stopping tolerance, then there is no improvement\n",
    "    lr_scheduler_factor=0.1,\n",
    "    lr_scheduler_step='8, 10, 12' #if epochs were 50, '25, 30, 35'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "hyperparameter_ranges={\n",
    "    \"learning_rate\":ContinuousParameter(0.01,0.1),\n",
    "    \"mini_batch_size\":CategoricalParameter([8,16,32]), # if we had a larger dataset ([256,512,1024])\n",
    "    \"optimizer\":CategoricalParameter([\"sgd\", \"adam\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name=\"validation:accuracy\"\n",
    "objective_type=\"Maximize\"\n",
    "max_jobs=5 # we have a small dataset\n",
    "max_parallel_jobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator=img_classifier_model,\n",
    "                            objective_metric_name=objective_metric_name,\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type=objective_type,\n",
    "                            max_jobs=max_jobs,\n",
    "                            max_parallel_jobs=max_parallel_jobs\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "model_inputs={\n",
    "    \"train\":sagemaker.inputs.TrainingInput(s3_data=f\"s3://{bucket}/train/\", content_type=\"application/x-image\"),\n",
    "    \"validation\":sagemaker.inputs.TrainingInput(s3_data=f\"s3://{bucket}/test/\", content_type=\"application/x-image\"),\n",
    "    \"train_lst\":sagemaker.inputs.TrainingInput(s3_data=f\"s3://{bucket}/train.lst/\", content_type=\"application/x-image\"),\n",
    "    \"validation_lst\":sagemaker.inputs.TrainingInput(s3_data=f\"s3://{bucket}/test.lst/\", content_type=\"application/x-image\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "job_name_prefix=\"classifier\"\n",
    "timestamp=time.strftime(\"-%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "job_name=job_name_prefix+timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs=model_inputs,job_name=job_name,logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sagemaker.model.Model(\n",
    "    image_uri = algorithm_image, #re-run algorithm image cell,\n",
    "    model_data = 'get/the/s3 URI of the best model',\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name='Demo-image-classifier-Pneumonia'\n",
    "\n",
    "deployment = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once endpoint is deployed, run local inference\n",
    "from sagemaker.predictor import Predictor\n",
    "predictor = Predictor(\"Demo-image-classifier-Pneumonia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "import base64\n",
    "\n",
    "file_name = 'data/chest_xray/val/val_normal0.jpeg'\n",
    "predictor.serializer=IdentitySerializer(\"image/jpeg\")\n",
    "with open (file_name, \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "inference=predictor.predict(data=payload)\n",
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix, precision, recall, deserialization\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "file_path = 'data/chest_xray/val/*.jpeg'\n",
    "files=glob.glob(file_path)\n",
    "\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "\n",
    "def make_pred():\n",
    "    for file in files:\n",
    "        if \"normal\" in file:\n",
    "            with open (file, 'rb') as f:\n",
    "                payload = f.read()\n",
    "                inference = predictor.predicst(data=payload).decode(\"utf-8\")\n",
    "                result = json.loads(inference)\n",
    "                predicted_class = np.argmax(result)\n",
    "                y_true.append(0)\n",
    "                y_pred.append(predicted_class)\n",
    "        elif \"pneumonia\" in file:\n",
    "            with open (file, 'rb') as f:\n",
    "                payload = f.read()\n",
    "                inference = predictor.predict(data=payload).decode(\"utf-8\")\n",
    "                result = json.loads(inference)\n",
    "                predicted_class = np.argmax(result)\n",
    "                y_true.append(1)\n",
    "                y_pred.append(predicted_class)\n",
    "\n",
    "make_pred()\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
